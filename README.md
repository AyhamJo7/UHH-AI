# üèõÔ∏è University AI Assistant

Welcome to our university‚Äôs very own self-hosted AI assistant! This project combines modern open-source AI tooling to give our staff and students a secure, private, and extremely helpful ‚ÄúChatGPT-style‚Äù assistant that *knows* our internal documentation (even those old PDFs with questionable scan quality...).

This assistant can:
- Answer questions from our HR/policy PDFs, onboarding documents, legal texts, and more.
- Use **OCR** (optical character recognition) so even scanned/photographed documents become part of its knowledge base.
- Be run entirely **within our university‚Äôs intranet**‚Äîno cloud, no data leaks, no excuses!
- Scale as our university‚Äôs documentation grows, with easy updates and bulk ingestion.

> **Everything is built by and for our university team. You‚Äôre not just a user‚Äîyou‚Äôre a co-creator!**

---

## üóÇÔ∏è Project Structure

Here‚Äôs how the repository is organized. This structure makes it easy for developers to find what they need and for future contributors to not lose their sanity.

```
UHH-AI/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openwebui_client.py
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ document_service.py
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ initial_ingest.py   # Bulk-ingest PDFs into OpenWebUI
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ logger.py
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatWindow.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageBubble.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ UploadArea.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Navbar.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ api.ts
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ tsconfig.json
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture.png
‚îÇ   ‚îî‚îÄ‚îÄ IMPLEMENTATION_GUIDE.md
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

---

## üß© How Everything Connects (Architecture Overview)

### Diagram

![Architecture Diagram](docs/architecture.png)

**Explanation of the Flow:**

1. **User** (staff/student) opens a browser and visits the AI Assistant web page on the intranet.
2. The **React frontend** (our beautiful UI) allows users to:
    - Ask questions in a chat-like interface.
    - Upload PDFs (policies, contracts, onboarding docs‚Äîbring ‚Äôem all).
3. Frontend sends chat/file requests to our **Python FastAPI backend**, which acts as the ‚Äúbouncer‚Äù and business logic layer.
4. Backend uses the **OpenWebUI API** (running in its own Docker container) to:
    - Send user questions (and, if needed, tell the AI to use certain uploaded PDFs as ‚Äúcontext‚Äù for answers).
    - Upload and index new documents.
5. **OpenWebUI** is the real ‚ÄúAI orchestrator‚Äù:
    - Calls **Ollama** for local language model inference (e.g., LLaMA-2).
    - When a new PDF is uploaded, passes it to **Apache Tika** for OCR/text extraction.
    - Splits the text into ‚Äúchunks,‚Äù embeds them for search, and stores them in its internal **vector database (Chroma)**.
    - When a user asks a question, does a semantic search over these embeddings to find the most relevant info (‚ÄúRAG‚Äù: retrieval-augmented generation), and passes it to the LLM for an answer.
6. The **answer** travels back up the chain (OpenWebUI ‚Üí backend ‚Üí frontend ‚Üí user).
7. The whole system runs entirely on university-owned servers. Data never leaves our campus!

---

## üõ†Ô∏è Tech Stack

- **Frontend:** React + TypeScript + Tailwind CSS
- **Backend:** Python (FastAPI)
- **AI Engine:** OpenWebUI (containerized)
- **Local LLM:** Ollama (with LLaMA-2 or similar models)
- **OCR:** Apache Tika
- **Vector DB:** Chroma (managed by OpenWebUI)
- **Containerization:** Docker & Docker Compose
- **Bulk PDF Ingestion:** Python script (`backend/scripts/initial_ingest.py`)
- **Documentation:** Markdown (docs/), inline code comments

---

## üöÄ Quickstart (Getting it Running)

### 1. Clone the Repo

```bash
git clone https://github.com/AyhamJo7/UHH-AI.git
```

### 2. Copy & Edit Environment Config

```bash
cp .env.example .env
```

Set your OpenWebUI API key, base URLs, etc. in the `.env` file.

### 3. Bulk-Upload PDFs (once)

- Place your PDFs in a local folder (see `IMPLEMENTATION_GUIDE.md` for naming tips).
- Run:

```bash
python backend/scripts/initial_ingest.py
```

> ‚ö†Ô∏è Only do this once per PDF! Script logs uploads and skips already-uploaded docs.

### 4. Start Everything

```bash
docker-compose up -d
```

This will launch backend, frontend, OpenWebUI, Ollama, and Tika‚Äîall networked together.

### 5. Use It!

- Go to the web page (usually [http://localhost:5000](http://localhost:5000) or whatever port you mapped).
- Start chatting, upload docs, and let the AI do the rest!

---

## üßë‚Äçüíª For Developers

- Want to develop the backend?  
  See `docs/IMPLEMENTATION_GUIDE.md` for file-by-file explanations, API call samples, and dev tips.

- Frontend changes?  
  Just edit React components, run `npm start` in `frontend/`, and see changes live.

- Extending with more AI models, or want to improve OCR?  
  There are notes in the implementation guide!

---

## ü§ù Thanks!

Big thanks to all team members who contribute, test, or bring snacks to late-night coding sessions.  
You make this campus project work!
