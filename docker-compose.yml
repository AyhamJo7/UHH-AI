# Define version
version: "3.8"

services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:ollama
    container_name: openwebui
    restart: unless-stopped
    ports:
      - "3000:3000"               # OpenWebUI API/UI
    volumes:
      - openwebui_data:/app/backend/data
      - ollama_models:/root/.ollama
    environment:
      - TIKA_URL=http://tika:9998
      - OPENWEBUI_API_KEY=${OPENWEBUI_API_KEY}

  ollama:
    # (optional, if not bundled in openwebui image)
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"             # Ollama inference API
    volumes:
      - ollama_models:/root/.ollama

  tika:
    image: apache/tika:latest-full
    container_name: tika
    restart: unless-stopped
    ports:
      - "9998:9998"               # Tika OCR service

  backend:
    build: ./backend
    container_name: backend
    restart: unless-stopped
    ports:
      - "5000:5000"               # FastAPI backend
    env_file:
      - .env
    depends_on:
      - openwebui
      - tika

  frontend:
    build: ./frontend
    container_name: frontend
    restart: unless-stopped
    ports:
      - "8080:80"                 # Nginx or static server for React build
    depends_on:
      - backend

volumes:
  openwebui_data:
  ollama_models:
